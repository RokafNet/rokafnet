{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Import Modules\n",
    "\n",
    "# %%\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor, WhisperProcessor\n",
    "\n",
    "import re\n",
    "import librosa\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Fix Seed\n",
    "\n",
    "# %%\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Config\n",
    "\n",
    "# %%\n",
    "CFG = {\n",
    "    'model': 'openai/whisper-tiny',\n",
    "    'sr': 16000,\n",
    "    'noise_file_path': '../files/noise.wav'\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Read Files\n",
    "\n",
    "# %%\n",
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'\n",
    "\n",
    "# %%\n",
    "df = pd.read_csv(f'{TRAIN_PATH}/texts.csv', index_col=False)\n",
    "submission = pd.read_csv(f'sample_submission.csv', index_col=False)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Label Cleaning\n",
    "\n",
    "# %%\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "# %%\n",
    "# label cleaning (remove punctuations)\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x, False))\n",
    "\n",
    "# remove outlier data\n",
    "df = df[df['filenames'] != 'audio_5497.wav']\n",
    "\n",
    "if not os.path.exists('preprocess'):\n",
    "    os.mkdir('preprocess')\n",
    "\n",
    "df.to_csv('preprocess/clean_df.csv', index=False)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Split long/short dataframe\n",
    "\n",
    "# %%\n",
    "def split_dataframe(df, df_name, is_train=True):\n",
    "    df_long = []\n",
    "    df_short = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        if is_train:\n",
    "            path = TRAIN_PATH + row['filenames']\n",
    "        else:\n",
    "            path = row['path']\n",
    "        wav, fs = librosa.load(path)\n",
    "        length = len(wav)/fs\n",
    "\n",
    "        if length >= 30:\n",
    "            df_long.append(row)\n",
    "        else:\n",
    "            df_short.append(row)\n",
    "\n",
    "    df_long = pd.DataFrame(df_long, columns=df.columns)\n",
    "    df_short = pd.DataFrame(df_short, columns=df.columns)\n",
    "\n",
    "    df_long.to_csv(f'preprocess/long_{df_name}.csv', index=False)\n",
    "    df_short.to_csv(f'preprocess/short_{df_name}.csv', index=False)\n",
    "\n",
    "\n",
    "# %%\n",
    "split_dataframe(df, 'df')\n",
    "split_dataframe(submission, 'test', False)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Preprocess & Train Dataset\n",
    "\n",
    "# %%\n",
    "# load feature extractor and tokenizer\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CFG['model'])\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "_, noise_array = wavfile.read(CFG[\"noise_file_path\"])\n",
    "\n",
    "\n",
    "# %%\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'], y_noise = noise_array)\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "    \n",
    "    # target text -> label ids(by tokenizer)\n",
    "    batch['labels'] = tokenizer(batch['transcripts']).input_ids\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "# %%\n",
    "def create_train_datasets(df, dir_name='dataset'):\n",
    "    # create dataset from csv\n",
    "    ds = Dataset.from_dict({\"audio\": [f'{TRAIN_PATH}/{file_path}' for file_path in df[\"filenames\"]],\n",
    "                        \"transcripts\": [text for text in df[\"text\"]]}).cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "\n",
    "    # train/valid split\n",
    "    train_valid = ds.train_test_split(test_size=0.2)\n",
    "    train_valid_dataset = DatasetDict({\n",
    "        \"train\": train_valid[\"train\"],\n",
    "        \"valid\": train_valid[\"test\"]})\n",
    "    \n",
    "    train_valid_dataset = train_valid_dataset.map(prepare_dataset, remove_columns = train_valid_dataset.column_names['train'], num_proc=4)\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    train_valid_dataset.save_to_disk(dir_name)\n",
    "\n",
    "\n",
    "# %%\n",
    "# create_train_datasets(df)\n",
    "\n",
    "# create long/short train dataset from csv files\n",
    "# long_df = pd.read_csv('preprocess/long_df.csv', index_col=False)\n",
    "short_df = pd.read_csv('preprocess/short_df.csv', index_col=False)\n",
    "\n",
    "# create_train_datasets(long_df, dir_name='dataset_long')\n",
    "create_train_datasets(short_df, dir_name='dataset_short')\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Test Dataset\n",
    "\n",
    "# %%\n",
    "def prepare_test_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'], y_noise = noise_array)\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "# %%\n",
    "def create_test_dataset(df, dir_name='dataset_test'):\n",
    "    # create dataset from csv\n",
    "    test_dataset = Dataset.from_dict({\"audio\": [file_path for file_path in df[\"path\"]]})\n",
    "    test_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "    sampling_rate = test_dataset.features['audio'].sampling_rate\n",
    "\n",
    "    # test data preprocess\n",
    "    test_dataset = test_dataset.map(prepare_test_dataset, remove_columns = test_dataset.column_names, num_proc=4)\n",
    "\n",
    "    # save test dataset\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    test_dataset.save_to_disk(dir_name)\n",
    "\n",
    "\n",
    "# %%\n",
    "create_test_dataset(submission)\n",
    "\n",
    "# create long/short test dataset from csv files\n",
    "# long_test = pd.read_csv('preprocess/long_test.csv', index_col=False)\n",
    "# short_test = pd.read_csv('preprocess/short_test.csv', index_col=False)\n",
    "\n",
    "# create_test_dataset(long_test, dir_name='dataset_long_test')\n",
    "# create_test_dataset(short_test, dir_name='dataset_short_test')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Import Modules\n",
    "\n",
    "# %%\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor, WhisperProcessor\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "import evaluate\n",
    "import re\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Fix Seed\n",
    "\n",
    "# %%\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "seed_everything()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Config\n",
    "\n",
    "# %%\n",
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'\n",
    "\n",
    "# %%\n",
    "CFG = {\n",
    "    'model': 'openai/whisper-tiny',\n",
    "    'sr': 16000,\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training\n",
    "\n",
    "# %%\n",
    "# Load train dataset created by preprocess notebook\n",
    "train_valid_dataset = load_from_disk('dataset_short')\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Data Collator\n",
    "\n",
    "# %%\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 인풋 데이터와 라벨 데이터의 길이가 다르며, 따라서 서로 다른 패딩 방법이 적용되어야 한다. 그러므로 두 데이터를 분리해야 한다.\n",
    "        # 먼저 오디오 인풋 데이터를 간단히 토치 텐서로 반환하는 작업을 수행한다.\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenize된 레이블 시퀀스를 가져온다.\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # 레이블 시퀀스에 대해 최대 길이만큼 패딩 작업을 실시한다.\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 패딩 토큰을 -100으로 치환하여 loss 계산 과정에서 무시되도록 한다.\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 이전 토크나이즈 과정에서 bos 토큰이 추가되었다면 bos 토큰을 잘라낸다.\n",
    "        # 해당 토큰은 이후 언제든 추가할 수 있다.\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "# %%\n",
    "# processor, tokenizer, feature extractor 로드\n",
    "processor = WhisperProcessor.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CFG['model'])\n",
    "\n",
    "# %%\n",
    "# 데이터 콜레이터 초기화\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Evaluation Metrics\n",
    "\n",
    "# %%\n",
    "metric = evaluate.load('cer')\n",
    "\n",
    "\n",
    "# %%\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "# %%\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # pad_token을 -100으로 치환\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # metrics 계산 시 special token들을 빼고 계산하도록 설정\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # 문장부호 + 띄어쓰기 제거하고 계산\n",
    "    pred_str = [clean_text(text) for text in pred_str]\n",
    "    label_str = [clean_text(text) for text in label_str]\n",
    "\n",
    "    cer = metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    return {\"cer\": cer}\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Load Pretrained Checkpoint\n",
    "\n",
    "# %%\n",
    "model = WhisperForConditionalGeneration.from_pretrained(CFG['model'])\n",
    "\n",
    "# %%\n",
    "# restrict prediction language to korean\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='korean', task='transcribe')\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n",
    "\n",
    "# %%\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    torch_compile=True, # for optimize code\n",
    "\n",
    "    output_dir=\"checkpoint\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    num_train_epochs=10,\n",
    "    optimizers=(AdamW, get_cosine_schedule_with_warmup),\n",
    "\n",
    "    fp16=True,\n",
    "\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=560,\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    dataloader_num_workers=8,\n",
    "    \n",
    "    save_strategy='steps',\n",
    "    save_steps=560,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"wandb\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# %%\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# %%\n",
    "trainer.train()\n",
    "\n",
    "# %%\n",
    "## save checkpoint\n",
    "MODEL_PATH = 'model'\n",
    "trainer.save_model(MODEL_PATH)\n",
    "\n",
    "# %%\n",
    "# set wandb to save all codes, weights, and results\n",
    "wandb.save(\"*.py\")\n",
    "wandb.save(\"*.ipynb\")\n",
    "\n",
    "wandb.save(\"*.pt\")\n",
    "wandb.save(\"*.pth\")\n",
    "wandb.save(\"*.hdf5\")\n",
    "\n",
    "wandb.save(\"*.csv\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Predict\n",
    "\n",
    "# %%\n",
    "# restrict prediction language to korean\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='korean', task='transcribe')\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "# %%\n",
    "# load test dataset created by preprocess notebook\n",
    "test_dataset = load_from_disk('dataset_test')\n",
    "len(test_dataset)\n",
    "\n",
    "# %%\n",
    "test_args = Seq2SeqTrainingArguments(\n",
    "    torch_compile=True, # for optimize code\n",
    "\n",
    "    output_dir=\"repo_name\",\n",
    "\n",
    "    per_device_eval_batch_size=32,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    dataloader_num_workers=8,\n",
    "    \n",
    "    logging_steps=25,\n",
    "    # report_to=[\"wandb\"],\n",
    ")\n",
    "\n",
    "# %%\n",
    "# inference\n",
    "test_trainer = Seq2SeqTrainer(args=test_args,\n",
    "                              model=model)\n",
    "pred = test_trainer.predict(test_dataset)\n",
    "\n",
    "# %%\n",
    "text = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Submit\n",
    "\n",
    "# %%\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['text'] = text\n",
    "submission.to_csv('raw_submission.csv', index=False)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Install Modules\n",
    "\n",
    "# %%\n",
    "# %pip install evaluate\n",
    "# %pip install swifter\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Import Modules\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import swifter\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Load Raw Submission\n",
    "\n",
    "# %%\n",
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'\n",
    "\n",
    "# %%\n",
    "df = pd.read_csv(TRAIN_PATH + 'texts.csv')\n",
    "raw_submission = pd.read_csv('raw_submission.csv')\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Remove Duplicates\n",
    "\n",
    "# %%\n",
    "def remove_duplicates(s):\n",
    "    l = s.split(\" \")\n",
    "    while len(l) >= 2 and l[-1] == l[-2]:\n",
    "        l = l[:-1]\n",
    "    return \" \".join(l)\n",
    "\n",
    "\n",
    "# %%\n",
    "raw_submission[\"text\"] = raw_submission[\"text\"].apply(remove_duplicates)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Proofreading with train labels\n",
    "\n",
    "# %%\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "# %%\n",
    "targets = list(map(lambda x : clean_text(x), set(df['text'].tolist()))) # train label값\n",
    "threshold = 41 # text길이\n",
    "cer_threshold = 0.5\n",
    "metric = evaluate.load('cer')\n",
    "\n",
    "def get_close(pred):\n",
    "    if len(pred) >= threshold:\n",
    "        return pred\n",
    "    min_cer = 1e8\n",
    "    index = -1\n",
    "    for j in range(len(targets)):\n",
    "        target = targets[j]\n",
    "        if len(target) >= threshold:\n",
    "            continue\n",
    "        if len(target) > len(pred) * 2:\n",
    "            continue\n",
    "        if len(pred) > len(target) * 1.5:\n",
    "            continue \n",
    "        cnt = 0\n",
    "        for ch in target:\n",
    "            if ch in pred:\n",
    "                cnt += 1\n",
    "        if cnt * 2 < len(target):\n",
    "            continue\n",
    "        cer = metric.compute(predictions=[pred], references=[target])\n",
    "        if min_cer > cer:\n",
    "            min_cer = cer\n",
    "            index = j\n",
    "    if min_cer < cer_threshold:\n",
    "        pred = targets[index]\n",
    "    return pred\n",
    "\n",
    "\n",
    "# %%\n",
    "targets = list(map(lambda x : clean_text(x), set(df['text'].tolist()))) #train label값\n",
    "preds = raw_submission['text'].apply(lambda x : clean_text(x))# predict 값\n",
    "\n",
    "tqdm.pandas()\n",
    "preds = preds.swifter.progress_bar(True).allow_dask_on_strings(enable=True).apply(get_close)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Export processed Submission\n",
    "\n",
    "# %%\n",
    "submission = raw_submission\n",
    "submission['text'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
