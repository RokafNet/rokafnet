{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Import Modules\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import IPython.display as ipd\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Fix Seed\n",
    "\n",
    "# %%\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "seed_everything()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Config\n",
    "\n",
    "# %%\n",
    "CFG = {\n",
    "    'model': 'openai/whisper-tiny',\n",
    "    'sr': 16000,\n",
    "    'noise_file_path': '../files/noise.wav'\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Read Files\n",
    "\n",
    "# %%\n",
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'\n",
    "\n",
    "# %%\n",
    "df = pd.read_csv(f'{TRAIN_PATH}/texts.csv', index_col=False)\n",
    "submission = pd.read_csv(f'sample_submission.csv', index_col=False)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Cleaning\n",
    "\n",
    "# %%\n",
    "import re\n",
    "\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text\n",
    "\n",
    "# %%\n",
    "# Label Cleaning (remove punctuations)\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x, False))\n",
    "\n",
    "# remove outlier data\n",
    "df = df[df['filenames'] != 'audio_5497.wav']\n",
    "\n",
    "if not os.path.exists('preprocess'):\n",
    "    os.mkdir('preprocess')\n",
    "\n",
    "df.to_csv('preprocess/clean_df.csv', index=False)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Split long/short dataframe\n",
    "\n",
    "# %%\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def split_dataframe(df, df_name, is_train=True):\n",
    "    df_long = []\n",
    "    df_short = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        if is_train:\n",
    "            path = TRAIN_PATH + row['filenames']\n",
    "        else:\n",
    "            path = row['path']\n",
    "        wav, fs = librosa.load(path)\n",
    "        length = len(wav)/fs\n",
    "\n",
    "        if length >= 30:\n",
    "            df_long.append(row)\n",
    "        else:\n",
    "            df_short.append(row)\n",
    "\n",
    "    df_long = pd.DataFrame(df_long, columns=df.columns)\n",
    "    df_short = pd.DataFrame(df_short, columns=df.columns)\n",
    "\n",
    "    df_long.to_csv(f'preprocess/long_{df_name}.csv', index=False)\n",
    "    df_short.to_csv(f'preprocess/short_{df_name}.csv', index=False)\n",
    "\n",
    "# %%\n",
    "split_dataframe(df, 'df')\n",
    "split_dataframe(submission, 'test', False)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Preprocess & Train Dataset\n",
    "\n",
    "# %%\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
    "from transformers import WhisperProcessor\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# load feature extractor and tokenizer\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CFG['model'])\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "_, noise_array = wavfile.read(CFG[\"noise_file_path\"])\n",
    "\n",
    "# %%\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'], y_noise = noise_array)\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "    \n",
    "    # target text -> label ids(by tokenizer)\n",
    "    batch['labels'] = tokenizer(batch['transcripts']).input_ids\n",
    "\n",
    "    return batch\n",
    "\n",
    "# %%\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "def create_train_datasets(df, dir_name='dataset'):\n",
    "    # create dataset from csv\n",
    "    ds = Dataset.from_dict({\"audio\": [f'{TRAIN_PATH}/{file_path}' for file_path in df[\"filenames\"]],\n",
    "                        \"transcripts\": [text for text in df[\"text\"]]}).cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "\n",
    "    # train/valid split\n",
    "    train_valid = ds.train_test_split(test_size=0.2)\n",
    "    train_valid_dataset = DatasetDict({\n",
    "        \"train\": train_valid[\"train\"],\n",
    "        \"valid\": train_valid[\"test\"]})\n",
    "    \n",
    "    train_valid_dataset = train_valid_dataset.map(prepare_dataset, remove_columns = train_valid_dataset.column_names['train'], num_proc=4)\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    train_valid_dataset.save_to_disk(dir_name)\n",
    "\n",
    "# %%\n",
    "# create_train_datasets(df)\n",
    "\n",
    "# create long/short train dataset from csv files\n",
    "# long_df = pd.read_csv('preprocess/long_df.csv', index_col=False)\n",
    "short_df = pd.read_csv('preprocess/short_df.csv', index_col=False)\n",
    "\n",
    "# create_train_datasets(long_df, dir_name='dataset_long')\n",
    "create_train_datasets(short_df, dir_name='dataset_short')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Test Dataset\n",
    "\n",
    "# %%\n",
    "def prepare_test_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'], y_noise = noise_array)\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "\n",
    "    return batch\n",
    "\n",
    "# %%\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "def create_test_dataset(df, dir_name='dataset_test'):\n",
    "    # create dataset from csv\n",
    "    test_dataset = Dataset.from_dict({\"audio\": [file_path for file_path in df[\"path\"]]})\n",
    "    test_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "    sampling_rate = test_dataset.features['audio'].sampling_rate\n",
    "\n",
    "    # test data preprocess\n",
    "    test_dataset = test_dataset.map(prepare_test_dataset, remove_columns = test_dataset.column_names, num_proc=4)\n",
    "\n",
    "    # save test dataset\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    test_dataset.save_to_disk(dir_name)\n",
    "\n",
    "# %%\n",
    "create_test_dataset(submission)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Import Modules\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import IPython.display as ipd\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Fix Seed\n",
    "\n",
    "# %%\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "seed_everything()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Config\n",
    "\n",
    "# %%\n",
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'\n",
    "\n",
    "# %%\n",
    "CFG = {\n",
    "    'model': 'seastar105/whisper-small-ko-zeroth',\n",
    "    'sr': 16000,\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# preprocess - read files 삽입 자리\n",
    "\n",
    "# %% [markdown]\n",
    "# preprocess - data cleaning 삽입 자리\n",
    "\n",
    "# %% [markdown]\n",
    "# preprocess - Data Preprocess & Train Dataset 삽입 자리\n",
    "\n",
    "# %% [markdown]\n",
    "# preprocess - Test Dataset 삽입 자리\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training\n",
    "\n",
    "# %%\n",
    "from datasets import load_from_disk\n",
    "train_valid_dataset = load_from_disk('dataset_short')\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Data Collator\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 인풋 데이터와 라벨 데이터의 길이가 다르며, 따라서 서로 다른 패딩 방법이 적용되어야 한다. 그러므로 두 데이터를 분리해야 한다.\n",
    "        # 먼저 오디오 인풋 데이터를 간단히 토치 텐서로 반환하는 작업을 수행한다.\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenize된 레이블 시퀀스를 가져온다.\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # 레이블 시퀀스에 대해 최대 길이만큼 패딩 작업을 실시한다.\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 패딩 토큰을 -100으로 치환하여 loss 계산 과정에서 무시되도록 한다.\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 이전 토크나이즈 과정에서 bos 토큰이 추가되었다면 bos 토큰을 잘라낸다.\n",
    "        # 해당 토큰은 이후 언제든 추가할 수 있다.\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "# %%\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "# 훈련시킬 모델의 processor, tokenizer, feature extractor 로드\n",
    "processor = WhisperProcessor.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CFG['model'])\n",
    "\n",
    "# %%\n",
    "# 데이터 콜레이터 초기화\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Evaluation Metrics\n",
    "\n",
    "# %%\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('cer')\n",
    "\n",
    "# %%\n",
    "import re\n",
    "\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text\n",
    "\n",
    "# %%\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # pad_token을 -100으로 치환\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # metrics 계산 시 special token들을 빼고 계산하도록 설정\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # 문장부호 + 띄어쓰기 제거하고 계산\n",
    "    pred_str = [clean_text(text) for text in pred_str]\n",
    "    label_str = [clean_text(text) for text in label_str]\n",
    "\n",
    "    cer = metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    return {\"cer\": cer}\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Pretrained Checkpoint\n",
    "\n",
    "# %%\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(CFG['model'])\n",
    "\n",
    "# %%\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='korean', task='transcribe')\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Training\n",
    "\n",
    "# %%\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    torch_compile=True, # for optimize code\n",
    "\n",
    "    output_dir=\"checkpoint\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    num_train_epochs=10,\n",
    "\n",
    "    fp16=True,\n",
    "\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=560,\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    dataloader_num_workers=8,\n",
    "    \n",
    "    save_strategy='steps',\n",
    "    save_steps=560,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"wandb\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# %%\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer = optimizer,\n",
    "                                            num_warmup_steps=500,\n",
    "                                            num_training_steps=3400)\n",
    "optimizers = (optimizer, scheduler)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    optimizers=optimizers,\n",
    ")\n",
    "\n",
    "# %%\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "MODEL_PATH = 'model'\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "trainer.save_model(MODEL_PATH)\n",
    "\n",
    "# %% [markdown]\n",
    "# !pip install wandb\n",
    "\n",
    "# %%\n",
    "import wandb\n",
    "\n",
    "# set wandb to save all codes, weights, and results\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Predict\n",
    "\n",
    "# %% [markdown]\n",
    "# preprocess - Test Dataset 삽입 자리\n",
    "\n",
    "# %%\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# %%\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='korean', task='transcribe')\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "# %%\n",
    "# load test dataset from local storage\n",
    "test_dataset = load_from_disk('dataset_test')\n",
    "\n",
    "# %%\n",
    "test_args = Seq2SeqTrainingArguments(\n",
    "    torch_compile=True, # for optimize code\n",
    "\n",
    "    output_dir=\"repo_name\",\n",
    "\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    dataloader_num_workers=8,\n",
    "    \n",
    "    logging_steps=25,\n",
    "    # report_to=[\"wandb\"],\n",
    ")\n",
    "\n",
    "# %%\n",
    "from transformers import pipeline\n",
    "\n",
    "# inference\n",
    "test_trainer = Seq2SeqTrainer(args=test_args,\n",
    "                              model=model)\n",
    "pred = test_trainer.predict(test_dataset)\n",
    "\n",
    "# %%\n",
    "text = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Submit\n",
    "\n",
    "# %%\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['text'] = text\n",
    "submission.to_csv('raw_submission.csv', index=False)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %%\n",
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'\n",
    "\n",
    "# %%\n",
    "df = pd.read_csv(TRAIN_PATH + 'texts.csv')\n",
    "raw_submission = pd.read_csv('raw_submission.csv')\n",
    "\n",
    "# %%\n",
    "def remove_duplicates(s):\n",
    "    l = s.split(\" \")\n",
    "    while len(l) >= 2 and l[-1] == l[-2]:\n",
    "        l = l[:-1]\n",
    "    return \" \".join(l)\n",
    "\n",
    "# %%\n",
    "print(remove_duplicates(\"같이 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진 사진\"))\n",
    "print(remove_duplicates(\"아 아 아 아 아\"))\n",
    "\n",
    "# %%\n",
    "raw_submission[\"text\"] = raw_submission[\"text\"].apply(remove_duplicates)\n",
    "\n",
    "# %%\n",
    "import re\n",
    "\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text\n",
    "\n",
    "# %%\n",
    "targets = list(map(lambda x : clean_text(x), set(df['text'].tolist()))) #train label값\n",
    "threshold = 41 # text길이\n",
    "cer_threshold = 0.7\n",
    "metric = evaluate.load('cer')\n",
    "def get_close(pred):\n",
    "    if len(pred) >= threshold:\n",
    "        return pred\n",
    "    min_cer = 1e8\n",
    "    index = -1\n",
    "    for j in range(len(targets)):\n",
    "        target = targets[j]\n",
    "        if len(target) >= threshold:\n",
    "            continue\n",
    "        if len(target) > len(pred) * 2:\n",
    "            continue\n",
    "        if len(pred) > len(target) * 1.5:\n",
    "            continue \n",
    "        cnt = 0\n",
    "        for ch in target:\n",
    "            if ch in pred:\n",
    "                cnt += 1\n",
    "        if cnt * 2 < len(target):\n",
    "            continue\n",
    "        cer = metric.compute(predictions=[pred], references=[target])\n",
    "        if min_cer > cer:\n",
    "            min_cer = cer\n",
    "            index = j\n",
    "    if min_cer < cer_threshold:\n",
    "        pred = targets[index]\n",
    "    return pred\n",
    "\n",
    "# %%\n",
    "import swifter\n",
    "targets = list(map(lambda x : clean_text(x), set(df['text'].tolist()))) #train label값\n",
    "preds = raw_submission['text'].apply(lambda x : clean_text(x))# predict 값\n",
    "\n",
    "tqdm.pandas()\n",
    "preds = preds.swifter.progress_bar(True).apply(get_close)\n",
    "    \n",
    "    \n",
    "\n",
    "# %%\n",
    "submission = raw_submission\n",
    "submission['text'] = preds\n",
    "\n",
    "# %%\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
