{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 05:59:48.696719: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 05:59:49.675484: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-11-30 05:59:49.675586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-11-30 05:59:49.675606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'model': 'openai/whisper-tiny',\n",
    "    'sr': 16000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{TRAIN_PATH}/texts.csv', index_col=False)\n",
    "submission = pd.read_csv(f'sample_submission.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Cleaning (remove punctuations)\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x, False))\n",
    "\n",
    "# remove outlier data\n",
    "df = df[df['filenames'] != '5497.wav']\n",
    "\n",
    "if not os.path.exists('preprocess'):\n",
    "    os.mkdir('preprocess')\n",
    "\n",
    "df.to_csv('preprocess/clean_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split long/short dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def split_dataframe(df, df_name, is_train=True):\n",
    "    df_long = []\n",
    "    df_short = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        if is_train:\n",
    "            path = TRAIN_PATH + row['filenames']\n",
    "        else:\n",
    "            path = row['path']\n",
    "        wav, fs = librosa.load(path)\n",
    "        length = len(wav)/fs\n",
    "\n",
    "        if length >= 30:\n",
    "            df_long.append(row)\n",
    "        else:\n",
    "            df_short.append(row)\n",
    "\n",
    "    df_long = pd.DataFrame(df_long, columns=df.columns)\n",
    "    df_short = pd.DataFrame(df_short, columns=df.columns)\n",
    "\n",
    "    df_long.to_csv(f'preprocess/long_{df_name}.csv', index=False)\n",
    "    df_short.to_csv(f'preprocess/short_{df_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb28075ea2e44dc19090a32bf8f0f5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64df896645d2495db34872701f2c6f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'filenames'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'filenames'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/root/rokafnet/code/preprocess.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m split_dataframe(df, \u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m split_dataframe(submission, \u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32m/root/rokafnet/code/preprocess.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df_short \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m tqdm(df\u001b[39m.\u001b[39miterrows()):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     path \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39;49m\u001b[39mfilenames\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_train:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B118.222.179.150/root/rokafnet/code/preprocess.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         path \u001b[39m=\u001b[39m TRAIN_PATH \u001b[39m+\u001b[39m path\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/usr/local/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'filenames'"
     ]
    }
   ],
   "source": [
    "# split_dataframe(df, 'df')\n",
    "split_dataframe(submission, 'test', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess & Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "# load feature extractor and tokenizer\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CFG['model'])\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'])\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "    \n",
    "    # target text -> label ids(by tokenizer)\n",
    "    batch['labels'] = tokenizer(batch['transcripts']).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "def create_train_datasets(df, dir_name='dataset'):\n",
    "    # create dataset from csv\n",
    "    ds = Dataset.from_dict({\"audio\": [f'{TRAIN_PATH}/{file_path}' for file_path in df[\"filenames\"]],\n",
    "                        \"transcripts\": [text for text in df[\"text\"]]}).cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "\n",
    "    # train/valid split\n",
    "    train_valid = ds.train_test_split(test_size=0.2)\n",
    "    train_valid_dataset = DatasetDict({\n",
    "        \"train\": train_valid[\"train\"],\n",
    "        \"valid\": train_valid[\"test\"]})\n",
    "    \n",
    "    train_valid_dataset = train_valid_dataset.map(prepare_dataset, remove_columns = train_valid_dataset.column_names['train'], num_proc=4)\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    train_valid_dataset.save_to_disk(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6331f1f95e0d48db87046897796ee856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/11087 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc988a72c4f4ab1b21c1d1948944592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2772 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create_train_datasets(df)\n",
    "\n",
    "# create long/short train dataset from csv files\n",
    "# long_df = pd.read_csv('preprocess/long_df.csv', index_col=False)\n",
    "short_df = pd.read_csv('preprocess/short_df.csv', index_col=False)\n",
    "\n",
    "# create_train_datasets(long_df, dir_name='dataset_long')\n",
    "create_train_datasets(short_df, dir_name='dataset_short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'])\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "def create_test_dataset(df, dir_name='dataset_test'):\n",
    "    # create dataset from csv\n",
    "    test_dataset = Dataset.from_dict({\"audio\": [file_path for file_path in df[\"path\"]]})\n",
    "    test_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "    sampling_rate = test_dataset.features['audio'].sampling_rate\n",
    "\n",
    "    # test data preprocess\n",
    "    test_dataset = test_dataset.map(prepare_test_dataset, remove_columns = test_dataset.column_names, num_proc=1)\n",
    "\n",
    "    # save test dataset\n",
    "    if not os.path.exists('test_dataset'):\n",
    "        os.mkdir('test_dataset')\n",
    "        \n",
    "    test_dataset.save_to_disk('test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dff354cf22c4abc95042712dbf7fe45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27df65d202af40c5b3df3878ef8c744f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/12 shards):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "create_test_dataset(submission)\n",
    "\n",
    "# create long/short test dataset from csv files\n",
    "long_test = pd.read_csv('preprocess/long_test.csv', index_col=False)\n",
    "short_test = pd.read_csv('preprocess/short_test.csv', index_col=False)\n",
    "\n",
    "create_train_datasets(long_test, dir_name='dataset_long_test')\n",
    "create_train_datasets(short_test, dir_name='dataset_short_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
