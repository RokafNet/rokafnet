{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "import noisereduce as nr\n",
    "\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor, WhisperProcessor\n",
    "\n",
    "import re\n",
    "import librosa\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'model': 'openai/whisper-tiny',\n",
    "    'sr': 16000,\n",
    "    'noise_file_path': '../files/noise.wav'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/mnt/elice/dataset/train/'\n",
    "TEST_PATH = '/mnt/elice/dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{TRAIN_PATH}/texts.csv', index_col=False)\n",
    "submission = pd.read_csv(f'sample_submission.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_space=True):\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\]','', text)\n",
    "    if remove_space:\n",
    "        text = ''.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label cleaning (remove punctuations)\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x, False))\n",
    "\n",
    "# remove outlier data\n",
    "df = df[df['filenames'] != 'audio_5497.wav']\n",
    "\n",
    "if not os.path.exists('preprocess'):\n",
    "    os.mkdir('preprocess')\n",
    "\n",
    "df.to_csv('preprocess/clean_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split long/short dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, df_name, is_train=True):\n",
    "    df_long = []\n",
    "    df_short = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        if is_train:\n",
    "            path = TRAIN_PATH + row['filenames']\n",
    "        else:\n",
    "            path = row['path']\n",
    "        wav, fs = librosa.load(path)\n",
    "        length = len(wav)/fs\n",
    "\n",
    "        if length >= 30:\n",
    "            df_long.append(row)\n",
    "        else:\n",
    "            df_short.append(row)\n",
    "\n",
    "    df_long = pd.DataFrame(df_long, columns=df.columns)\n",
    "    df_short = pd.DataFrame(df_short, columns=df.columns)\n",
    "\n",
    "    df_long.to_csv(f'preprocess/long_{df_name}.csv', index=False)\n",
    "    df_short.to_csv(f'preprocess/short_{df_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataframe(df, 'df')\n",
    "split_dataframe(submission, 'test', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess & Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature extractor and tokenizer\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CFG['model'])\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CFG['model'], language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "_, noise_array = wavfile.read(CFG[\"noise_file_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'], y_noise = noise_array)\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "    \n",
    "    # target text -> label ids(by tokenizer)\n",
    "    batch['labels'] = tokenizer(batch['transcripts']).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_datasets(df, dir_name='dataset'):\n",
    "    # create dataset from csv\n",
    "    ds = Dataset.from_dict({\"audio\": [f'{TRAIN_PATH}/{file_path}' for file_path in df[\"filenames\"]],\n",
    "                        \"transcripts\": [text for text in df[\"text\"]]}).cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "\n",
    "    # train/valid split\n",
    "    train_valid = ds.train_test_split(test_size=0.2)\n",
    "    train_valid_dataset = DatasetDict({\n",
    "        \"train\": train_valid[\"train\"],\n",
    "        \"valid\": train_valid[\"test\"]})\n",
    "    \n",
    "    train_valid_dataset = train_valid_dataset.map(prepare_dataset, remove_columns = train_valid_dataset.column_names['train'], num_proc=4)\n",
    "\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    train_valid_dataset.save_to_disk(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_train_datasets(df)\n",
    "\n",
    "# create long/short train dataset from csv files\n",
    "# long_df = pd.read_csv('preprocess/long_df.csv', index_col=False)\n",
    "short_df = pd.read_csv('preprocess/short_df.csv', index_col=False)\n",
    "\n",
    "# create_train_datasets(long_df, dir_name='dataset_long')\n",
    "create_train_datasets(short_df, dir_name='dataset_short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_dataset(batch):\n",
    "    audio = batch['audio']\n",
    "    reduced_noise_audio = nr.reduce_noise(y=audio['array'], sr=CFG['sr'], y_noise = noise_array)\n",
    "\n",
    "    # raw form(reduced_noise_audio) -> log-Mel spectrogram\n",
    "    batch['input_features'] = feature_extractor(reduced_noise_audio, sampling_rate=audio['sampling_rate']).input_features[0]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataset(df, dir_name='dataset_test'):\n",
    "    # create dataset from csv\n",
    "    test_dataset = Dataset.from_dict({\"audio\": [file_path for file_path in df[\"path\"]]})\n",
    "    test_dataset = test_dataset.cast_column(\"audio\", Audio(sampling_rate=CFG['sr']))\n",
    "    sampling_rate = test_dataset.features['audio'].sampling_rate\n",
    "\n",
    "    # test data preprocess\n",
    "    test_dataset = test_dataset.map(prepare_test_dataset, remove_columns = test_dataset.column_names, num_proc=4)\n",
    "\n",
    "    # save test dataset\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "        \n",
    "    test_dataset.save_to_disk(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test_dataset(submission)\n",
    "\n",
    "# create long/short test dataset from csv files\n",
    "# long_test = pd.read_csv('preprocess/long_test.csv', index_col=False)\n",
    "# short_test = pd.read_csv('preprocess/short_test.csv', index_col=False)\n",
    "\n",
    "# create_test_dataset(long_test, dir_name='dataset_long_test')\n",
    "# create_test_dataset(short_test, dir_name='dataset_short_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
